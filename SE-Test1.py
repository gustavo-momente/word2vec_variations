#!/usr/bin/python
__author__ = 'vilelag'

import os
import argparse
import subprocess
from multiprocessing import Pool
import itertools
import numpy as np
import shutil


def create_parsers():
    #parser for the main program
    parser = argparse.ArgumentParser(description='Run the task 2 of SemEval-2012 over a word representation dictionary')
    parser.add_argument('-w', '-words', metavar='<file.bin>', required=True,
                        help='Dictionary with word representations in readable form')
    parser.add_argument('-q', '-questions', metavar='<folder>', default='./SE2012/Training/Phase1Questions',
                        help='Folder with Phase 1 Questions"')
    parser.add_argument('-a', '-answers ', metavar='<folder>', default='./SE2012/Training/Phase1Answers',
                        help='Folder with Phase 1 Answers')
    parser.add_argument('-o', '-out', metavar='<folder>', default='./',
                        help="Output folder")
    parser.add_argument('-t', '-threads', metavar='<int>', nargs=1, default=[8], type=int,
                        help='Use <int> threads (default 8)')
    parser.add_argument('-threshold', metavar='<int>', nargs=1, default=[0], type=int,
                        help='Threshold to number of words being used (0: all, default: 0)')
    parser.add_argument('-SE', metavar='<folder>', default='./SE2012',
                        help='Folder with SE2012 files')
    parser.add_argument('-a2', '-answers2', metavar='<folder>', default='./SE2012/Training/Phase2Answers',
                        help='Folder with Phase 2 Answers')
    parser.add_argument('-np', '-nprune', metavar='<int>', nargs='?', default=1, const=0, type=int,
                        help='If present superfluous files won\'t be pruned (1 : Prune, else: Don\'t,'
                             ' Default: Prune)')
    return parser


def create_output_folder(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)


def read_word_representation(path, threshold):
    with open(path) as f:
        content = f.read().splitlines()
    data = dict()
    words, size = content[0].split(' ')
    words = int(words)
    size = int(size)
    if 0 < threshold < words:
        words = threshold

    for i in range(1, words+1):
        temp = content[i].split(' ')
        data[temp[0].upper()] = np.asarray([np.float64(x) for x in temp[1:-1]], dtype=np.float64)
        # Normalizing
        data[temp[0].upper()] *= 1 / np.linalg.norm(data[temp[0].upper()])

    return data


def get_file_list(dir, ext='.txt'):
    fl = []
    for f in os.listdir(dir):
        if f.endswith(ext):
            fl.append(dir+'/'+f)
    return fl


def get_class_base(question_f):
    with open(question_f) as f:
        content = f.read().splitlines()
    base = []
    for i in range(4, 7):
        base.append(content[i].split(':'))
    return base


def get_class_tests(answer_f):
    with open(answer_f) as f:
        content = f.read().splitlines()
    for i in xrange(len(content)):
        content[i] = content[i].lstrip('"').rstrip('"')
        content[i] = content[i].split(':')
    return content


def init_do_test(arg):
    return do_test(*arg)


def do_test(question_f, answer_f, output, words):
    base = get_class_base(question_f)
    tests = get_class_tests(answer_f)

    # calculating class 'representation'
    size_word = len(words.itervalues().next())
    class_representation = np.zeros(size_word)

    cases = 0
    for case in base:
        try:
            class_representation += words[case[1].upper()] - words[case[0].upper()]
            cases += 1
        except KeyError as e:
            # print '{} not in the dictionary!'.format(e.args)
            pass
        except IndexError:
            print 'IE'
            print case

    if cases != 0:
        class_representation = class_representation/cases

    #Calculating 'distances'
    tests_dic = dict()
    for case in tests:
        try:
            case_rep = words[case[1].upper()] - words[case[0].upper()]
            distance = 100 * np.dot(case_rep, class_representation)
        except KeyError:
            distance = 0
        tests_dic[':'.join(case)] = distance

    #Writing output
    f = open(output, mode='w')
    f.write('#\n#\tGenerated by:\t\t\t\tSE-Test1.py\n#\tPair File:\t\t\t\t{0}\n'.format(answer_f))
    f.write('#\tScaled File:\t\t\t\t{0}\n#\tNumber of Unique Pairs:\t\t\t{1}\n#\n'.format(output, len(tests)))
    for case in sorted(tests_dic, key=lambda x: tests_dic[x], reverse=True):
        f.write('{0:3.1f} "{1}"\n'.format(tests_dic[case], case))

    f.close()


def gen_out(questions, answers, out):
    q_tests = []
    a_tests = []
    o_tests = []
    t_answers = list(answers)
    for q in questions:
        case = q.split('-')[-1]
        for a in t_answers:
            case_a = a.split('-')[-1]
            if case_a == case:
                q_tests.append(q)
                a_tests.append(a)
                o_tests.append(out +'-{}'.format( case))
                t_answers.remove(a)
                break
    return q_tests, a_tests, o_tests


def init_ms(args):
    return ms(*args)


def ms(ans, out, ms_f):
    subprocess.check_output([ms_f, ans, out])


def init_ss(args):
    return ss(*args)


def ss(in1, in2, out, ss_f):
    subprocess.check_output([ss_f, in1, in2, out])


def get_score(afile):
    with open(afile) as f:
        content = f.read().splitlines()
    score = content[5].split(':')[-1]
    score = float(score.rstrip().lstrip())
    return score


def sort_func(x):
    x = x.split('-')[-1].rstrip('.txt')
    return int(x[:-1])*27+ord(x[-1].lower())-ord('a')


def gen_csv(out_ss, out):
    f = open(out, 'w')
    score = dict()
    for i in sorted(out_ss, key=sort_func):
        score[i] = get_score(i)
    f.write('Subcategories,Spearman\n')
    for i in sorted(out_ss, key=sort_func):
        f.write('{},{}\n'.format(i.split('-')[-1].rstrip('.txt'), score[i]))
    mean = 0

    for i in score.values():
        mean += i

    mean /= len(score)
    f.write('Average,{}\n'.format(mean))
    f.close()


def main():
    parser = create_parsers()
    args = vars(parser.parse_args())
    words_f = args['w']
    questions = args['q'].rstrip('/')
    answers = args['a'].rstrip('/')

    out = args['o'].rstrip('/')
    threads = args['t'][0]
    threshold = args['threshold'][0]
    answers2 = args['a2'].rstrip('/')
    se_folder = args['SE'].rstrip('/')

    prune = args['np']
    create_output_folder(out)
    words_rep = read_word_representation(words_f, threshold)
    questions = get_file_list(questions)
    answers = get_file_list(answers)
    answers2 = get_file_list(answers2)

    create_output_folder(out+'/myscore')
    q_tests, a_tests, o_tests = gen_out(questions, answers, out+'/myscore/SE-Test1Scaled')
    pool = Pool(threads)

    pool.map(init_do_test, itertools.izip(q_tests, a_tests, o_tests, itertools.repeat(words_rep)))

    #Running maxdiff_to_scale.pl
    create_output_folder(out+'/TurkerScaled')
    o_ms = []
    for i in answers2:
        ext = i.split('-')[-1]
        o_ms.append(out+'/TurkerScaled/TurkerScaled-{}'.format(ext))

    pool.map(init_ms, itertools.izip(answers2, o_ms, itertools.repeat(se_folder+'/maxdiff_to_scale.pl')))

    # out_ss = []
    create_output_folder(out+'/ScoreScale')
    # for i in sorted(answers):
    #     ext = i.split('/')[-1]
    #     out_ss.append(out+'/ScoreScale/Spearman{}'.format(ext))
    fname = answers[0].split('/')[-1]
    fname = fname.split('-')[0]
    o_ms, o_tests, out_ss = gen_out(o_ms, o_tests, out+'/ScoreScale/{}'.format(fname))

    pool.map(init_ss, itertools.izip(o_ms, o_tests, out_ss, itertools.repeat(se_folder+'/score_scale.pl')))
    gen_csv(out_ss, out+'/log.csv')

    # Delete superfluous data
    if prune == 1:
        shutil.rmtree(out+'/myscore')
        shutil.rmtree(out+'/TurkerScaled')
        shutil.rmtree(out+'/ScoreScale')

main()


